{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV method:StratifiedKFlod  Split number:  3\n",
      "Start:   current:  1    Total:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:122: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " 9200/46666 [====>.........................] - ETA: 1:37 - loss: 0.2836- ETA: 1:37 - loss: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-b889ae7d9c6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[0mmodel1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLSTM_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m     \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LSTM Done\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[0mmodel2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxgboost_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Stacking\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM,GRU\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn\n",
    "from keras import layers\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier as xgbc\n",
    "\n",
    "#ROC AUC\n",
    "def paintROC(y_test1,y_pred1):\n",
    "    fpr,tpr,threshold = roc_curve(y_test1, y_pred1) ###real p value/ false p value\n",
    "    roc_auc = auc(fpr,tpr) ###auc\n",
    "\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.plot(fpr, tpr, color='blue',\n",
    "            lw=lw, label='ROC curve (area = %0.4f)' % roc_auc) ###\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "#LSTM\n",
    "def LSTM_():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 128, input_length=maxlen))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop')\n",
    "    return model\n",
    "\n",
    "#XGBOOST\n",
    "def xgboost_():\n",
    "    model=xgbc(silent=0,\n",
    "        learning_rate=0.3,\n",
    "        min_child_weight=1,\n",
    "        max_depth=9,\n",
    "        gamma=0.3,\n",
    "        subsample=0.9,\n",
    "        max_delta_step=0,\n",
    "        colsample_bytree=0.8,\n",
    "        colsample_bylevel=1,\n",
    "        reg_alpha=0.01,\n",
    "        reg_lambda=1,\n",
    "        scale_pos_weight=1,\n",
    "        n_estimators=150,\n",
    "        objective='binary:logistic',\n",
    "        seed=0)\n",
    "    return model\n",
    "\n",
    "#CNN\n",
    "def CNN_1v():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 128, input_length=maxlen))\n",
    "    model.add(layers.Conv1D(32,5,activation='relu'))\n",
    "    model.add(layers.MaxPooling1D(3))\n",
    "    model.add(layers.Conv1D(32,5,activation='relu'))\n",
    "    model.add(layers.GlobalMaxPooling1D())\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop')\n",
    "    return model\n",
    "\n",
    "#Input data\n",
    "#indata=pd.read_csv(\"../input/DGA_test.csv\")\n",
    "indata=pd.read_csv(r'E:\\Data_test\\DGA_test.csv')\n",
    "\n",
    "X=indata['url']\n",
    "labels=indata['label']\n",
    "\n",
    "# Generate a dictionary of valid characters\n",
    "valid_chars = {x:idx+1 for idx, x in enumerate(set(''.join(X)))}\n",
    "\n",
    "max_features = len(valid_chars) + 1\n",
    "maxlen = np.max([len(x) for x in X])\n",
    "# Convert characters to int and pad\n",
    "X = [[valid_chars[y] for y in x] for x in X]\n",
    "X = sequence.pad_sequences(X, maxlen=maxlen)\n",
    "\n",
    "#Standardization\n",
    "#X=preprocessing.scale(X)\n",
    "y=np.array(labels)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold  \n",
    "cv_number=5# parameter\n",
    "skf= StratifiedKFold(n_splits=cv_number) # x-fold cv \n",
    "skf.get_n_splits(X,y) \n",
    "print(\"CV method:StratifiedKFlod  Split number: \",cv_number) \n",
    "\n",
    "ac_test=[]\n",
    "ac_train=[]\n",
    "ac_test_auc=[]\n",
    "ac_train_auc=[]\n",
    "term=1\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):  \n",
    "    print(\"Start:   current: \",term,\"  \",\"Total: \",cv_number) \n",
    "    time_start=time.time()\n",
    "    \n",
    "    X_train,X_test = X[train_index], X[test_index]  \n",
    "    y_train,y_test = y[train_index], y[test_index] \n",
    "    \n",
    "    model1=LSTM_()\n",
    "    model1.fit(X_train,y_train,batch_size=20,nb_epoch=1)\n",
    "    print(\"LSTM Done\")\n",
    "    model2=xgboost_()\n",
    "    model2.fit(X_train,y_train)\n",
    "    print(\"XGBoost Done\")\n",
    "    model3=CNN_1v()\n",
    "    model3.fit(X_train,y_train,batch_size=20,nb_epoch=1)\n",
    "    print(\"CNN Done\")\n",
    "    meta_data_train=np.c_[model1.predict(X_train),model2.predict_proba(X_train),model3.predict(X_train)]\n",
    "    \n",
    "    #model stacking\n",
    "    model_stack=LogisticRegression(class_weight='balanced')\n",
    "    model_stack.fit(meta_data_train,y_train)\n",
    "    meta_data_test=np.c_[model1.predict(X_test),model2.predict_proba(X_test),model3.predict(X_test)]\n",
    "    y_pred_test=model_stack.predict_proba(meta_data_test)[:,1] \n",
    "    y_pred_train=model_stack.predict_proba(meta_data_train)[:,1] \n",
    "    ac_test.append(metrics.accuracy_score(y_test.astype('int'), model_stack.predict(meta_data_test).astype('int')))\n",
    "    ac_train.append(metrics.accuracy_score(y_train.astype('int'),model_stack.predict(meta_data_train).astype('int')))\n",
    "    ac_test_auc.append(sklearn.metrics.roc_auc_score(y_test, y_pred_test))\n",
    "    ac_train_auc.append(sklearn.metrics.roc_auc_score(y_train,y_pred_train))\n",
    "    \n",
    "    time_end=time.time()\n",
    "    print(\"Time:\",round(time_end-time_start,4))\n",
    "    term+=1\n",
    "    \n",
    "    #plot roc_curve\n",
    "    paintROC(y_test,y_pred_test)\n",
    "    \n",
    "ac_test_auc=np.array(ac_test_auc)\n",
    "ac_train_auc=np.array(ac_train_auc)\n",
    "ac_test=np.array(ac_test)\n",
    "ac_train=np.array(ac_train)\n",
    "print(\"Mean Accuracy of Train Set: \",round(ac_train.mean(),4),'\\n'\n",
    "     \" Mean Accuracy of the Test Set:\",round(ac_test.mean(),4),'\\n'\n",
    "      \" Mean AUC of the Train Set:\",round(ac_train_auc.mean(),4),'\\n'\n",
    "      \" Mean AUC of the Test Set:\",round(ac_test_auc.mean(),4)\n",
    "     )\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
